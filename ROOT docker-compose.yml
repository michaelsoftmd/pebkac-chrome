version: '3.8'

networks:
  llm-network:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  swayvnc-wayvnc-certs:
    driver: local

  # New cache volumes
  redis-data:
    driver: local
    
  duckdb-data:
    driver: local
    driver_opts:
      type: none
      device: /mnt/ssd/podman/duckdb-data
      o: bind

services:
  # Ollama Service
  ollama:
    image: docker.io/ollama/ollama:latest
    container_name: ollama
    networks:
      - llm-network
    security_opt:
      - no-new-privileges
    volumes:
      - /mnt/ssd/podman/models/ollama:/root/.ollama
      - /mnt/ssd/podman/models/gguf:/import:ro
    ports:
      - "127.0.0.1:11434:11434"
    environment:
      - OLLAMA_NUM_GPU=0
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_MODELS=/root/.ollama
    restart: unless-stopped
    profiles: ["ollama"]

  # Llama.cpp with Vulkan
  llama-cpp-server:
    image: llama-vulkan
    container_name: llama-cpp-server
    networks:
      - llm-network
    devices:
      - /dev/dri:/dev/dri
      - /dev/kfd:/dev/kfd
    group_add:
      - video
      - # or your own
    security_opt:
      - label=disable
      - seccomp=unconfined
    volumes:
      - /mnt/ssd/podman/models/gguf:/models:ro
    ports:
      - "127.0.0.1:8080:8080"
    environment:
      - HSA_OVERRIDE_GFX_VERSION=10.3.0
      - VK_ICD_FILENAMES=/usr/share/vulkan/icd.d/radeon_icd.x86_64.json
      - GGML_VULKAN_DEVICE=0
    entrypoint: [
      "/app/llama-server",
      "-m", "/models/${LLAMACPP_MODEL:-$LLAMACPP_MODEL}",
      "--host", "0.0.0.0",
      "--port", "8080",
      "-ngl", "${LLAMACPP_GPU_LAYERS:-18}",
      "-t", "${LLAMACPP_THREADS:-4}",
      "-c", "${LLAMACPP_CONTEXT:-8192}",
      "-b", "${LLAMACPP_BATCH:-2048}",
      "-ub", "${LLAMACPP_UBATCH:-512}",
      "--flash-attn", "auto",
      "--mlock",
      "-sm", "layer",
      "--jinja",
      "-np", "${LLAMACPP_PARALLEL:-1}",
      "--ctx-shift",
      "--metrics"
    ]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    profiles: ["zendriver", "llamacpp", "full"]

  # Zendriver Browser Automation
  zendriver:
    build:
      context: ./zendriver-docker
    container_name: zendriver
    depends_on:
      - llama-cpp-server
      - redis-cache
      - duckdb-cache
    networks:
      - llm-network
    ports:
      - "127.0.0.1:8090:8080"
      - "127.0.0.1:5910:5910"
      - "127.0.0.1:6080:6080"
    volumes:
      - swayvnc-wayvnc-certs:/certs
    environment:
      - RENDER_GROUP_GID= #or your own
      - SWAY_RESOLUTION=${SWAY_RESOLUTION:-1280x720}
      - WAYVNC_PORT=5910
      - WAYVNC_ENABLE_AUTH=false
      - MESA_LOADER_DRIVER_OVERRIDE=radeonsi
      - LIBVA_DRIVER_NAME=radeonsi
      - VK_ICD_FILENAMES=/usr/share/vulkan/icd.d/radeon_icd.x86_64.json
      - ACTIVE_OPENAI_URL=http://llama-cpp-server:8080/v1
      - ZENDRIVER_API_URL=http://localhost:8080
      - DUCKDB_URL=http://duckdb-cache:9001
      - SMOLAGENTS_MAX_STEPS=${SMOLAGENTS_MAX_STEPS:-15}
      # Timeout Configuration
      - TIMEOUT_ELEMENT_FIND=${TIMEOUT_ELEMENT_FIND:-8}
      - TIMEOUT_HTTP_REQUEST=${TIMEOUT_HTTP_REQUEST:-15}
      - TIMEOUT_HTTP_EXTRACTION=${TIMEOUT_HTTP_EXTRACTION:-20}
      - TIMEOUT_PAGE_LOAD=${TIMEOUT_PAGE_LOAD:-25}
      # Extraction Configuration
      - EXTRACTION_WORD_LIMIT=${EXTRACTION_WORD_LIMIT:-350}
      - EXTRACTION_CONTENT_DISPLAY_CHARS=${EXTRACTION_CONTENT_DISPLAY_CHARS:-7500}
      - EXTRACTION_FAVOR_PRECISION=${EXTRACTION_FAVOR_PRECISION:-false}
      - EXTRACTION_INCLUDE_COMMENTS=${EXTRACTION_INCLUDE_COMMENTS:-false}
      - EXTRACTION_INCLUDE_TABLES=${EXTRACTION_INCLUDE_TABLES:-true}
      # Search Configuration
      - SEARCH_MAX_RESULTS_DEFAULT=${SEARCH_MAX_RESULTS_DEFAULT:-10}
      - SEARCH_MAX_RESULTS_LIMIT=${SEARCH_MAX_RESULTS_LIMIT:-50}
      # Cache Configuration
      - CACHE_TTL_NAVIGATION=${CACHE_TTL_NAVIGATION:-300}
      - CACHE_TTL_EXTRACTION=${CACHE_TTL_EXTRACTION:-3600}
      - CACHE_TTL_SEARCH=${CACHE_TTL_SEARCH:-1800}
      - CACHE_TTL_ELEMENT=${CACHE_TTL_ELEMENT:-86400}
      - AGENT_STREAM_CHUNK_SIZE=${AGENT_STREAM_CHUNK_SIZE:-75}
      - REDIS_URL=${REDIS_URL:-redis://redis-cache:6379}
    devices:
      - /dev/dri
      - /dev/kfd
    security_opt:
      - seccomp:unconfined
      - label:disable
    group_add:
      - video
      - "xxx" #or your own
    restart: unless-stopped
    profiles: ["zendriver", "llamacpp", "full"]

  # Redis Cache Service (L1 Cache)
  redis-cache:
    image: docker.io/redis:6.2
    container_name: redis-cache
    networks:
      - llm-network
    ports:
      - "127.0.0.1:6379:6379"
    volumes:
      - redis-data:/data
    command: [
      "redis-server",
      "--maxmemory", "512mb",
      "--maxmemory-policy", "allkeys-lru",
      "--save", "60", "1000",
      "--appendonly", "yes",
      "--appendfsync", "everysec"
    ]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
    restart: unless-stopped
    profiles: ["zendriver", "full"]

  # DuckDB Cache Service (L2 Cache)
  duckdb-cache:
    build:
      context: ./duckdb-service
      dockerfile: Dockerfile
    container_name: duckdb-cache
    networks:
      - llm-network
    ports:
      - "127.0.0.1:9001:9001"
    volumes:
      - duckdb-data:/data
      - /mnt/ssd/podman/cache:/cache
    environment:
      - DUCKDB_DATABASE=/data/cache.db
      - DUCKDB_MEMORY_LIMIT=1GB
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    profiles: ["zendriver", "full"]

